{
  
    
        "post0": {
            "title": "Biggest Dataset on Internet",
            "content": ". What are we doing? And Why? . If you are a datascientist or computer vision researcher who always looking for neat image or any sort of dataset because it&#39;s sometimes so hard to find right dataset for you. In this post, i am sharing some resources which would be super helpful for you. I will also show the right way to download them in case of Google Open Image Dataset. What right way you may ask? It&#39;s simply a python script which will do the job for you. You don&#39;t need to rush in anyway. . Open Images Dataset V6 . When i was starting out from scratch. It was quite difficult to know from where to download the dataset. Or if that dataset right for you. Open Images Dataset V6 by Google is an amazing source to download the data. . You can find it here. There will be plethora of categories in the dropdown menu. It would look something like this. . . Brief . As you can see, the category for this tutorial i have chosen is taxi. You may chose anything else, Ofcourse!. There are several filters on the top of red bar in the website which is important to know about. Like: . Subset : (Train, Validation) | Type: (Detection, Segementation) | . Subset is only to show you the content which will be downloaded if you download train or validation filtered data. . Type is crucial, it will give you whatever type of problem deal with. For example, for this example we have used detection. So the images we are getting is bounding boxes. If you switch it to, segmentation you get segemented image. As simple as that. . How to download? . It&#39;s quite difficult to ambigous to download from the website. But fortunately we have tool which makes it easy to one liner! . We use a tool name OIDv4_ToolKit available on github. It makes is fairly easy to download images. . Cloning the github repo. . Note: If you are running the command in a terminal. Omit &quot;!&quot; . . !git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git . Cloning into &#39;OIDv4_ToolKit&#39;... remote: Enumerating objects: 444, done. remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444 Receiving objects: 100% (444/444), 34.09 MiB | 35.95 MiB/s, done. Resolving deltas: 100% (157/157), done. . Moving inside directory and extracting some files. You don&#39;t need to bother much about this, just copy paste and run on your machine. . %cd OIDv4_ToolKit/ !curl &quot;https://d1vvhvl2y92vvt.cloudfront.net/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot; !unzip awscliv2.zip !sudo ./aws/install . Now, here comes the magic. One command where you specify : . class : In our case, we will download Taxi images. You can download multiple classes by just typing class one after another. | type_csv: Do you want to download train data? Validation data? | limit: How many images we want to download? I am downloading 100 as an example. | . !python main.py downloader --classes Taxi --type_csv train --limit 100 . ___ _____ ______ _ _ .&#39; `.|_ _||_ _ `. | | | | / .-. | | | | `. _ __ | |__| |_ | | | | | | | | | |[ [ ]|____ _| `-&#39; /_| |_ _| |_.&#39; / / / _| |_ `.___.&#39;|_____||______.&#39; __/ |_____| _____ _ _ (____ | | | | _ ___ _ _ _ ____ | | ___ ____ _ | | ____ ____ | | | / _ | | | | _ | |/ _ / _ |/ || |/ _ )/ ___) | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| | |_____/ ___/ ____|_| |_|_| ___/ _||_| ____| ____)_| [INFO] | Downloading Taxi. [ERROR] | Missing the class-descriptions-boxable.csv file. [DOWNLOAD] | Do you want to download the missing file? [Y/n] Y ...145%, 0 MB, 31097 KB/s, 0 seconds passed [DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv. [ERROR] | Missing the train-annotations-bbox.csv file. [DOWNLOAD] | Do you want to download the missing file? [Y/n] Y ...100%, 1138 MB, 33727 KB/s, 34 seconds passed [DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv. Taxi [INFO] | Downloading train images. [INFO] | [INFO] Found 1434 online images for train. [INFO] | Limiting to 100 images. [INFO] | Download of 100 images in train. 100% 100/100 [02:08&lt;00:00, 1.28s/it] [INFO] | Done! [INFO] | Creating labels for Taxi of train. [INFO] | Labels creation completed. . Sample image from data . Now it has been downloaded. Dataset will be downloaded in the file /OID/Dataset/train/ Let&#39;s see the sample image? . So it looks pretty good! Remember i have only downloaded 100 images. You can download with any limit. If its available on dataset. It will be downloaded. We also have bounding boxes in labels folder. . . Tip: csv file have been downloaded in csv_folder. You can use it as pandas dataframe for more flexible usage of data. . Open Public datasets . As a data scientist, you dont always deal with image dataset. So, this Github Repo got very detailed list of every dataset for gamut of professions. . . . Tip: If you are new to github. You can fork it and contribute to it as well. . Amazon, Google, Microsoft Public Dataset . Waait.. we just discussed google dataset a while ago. That was especially for image based problems. Incase you want to research for the data yourself that you struggling to find. The Google Dataset Search engine will help you to research more about it. . Like Google, Amazon also have some public dataset to help you with your research. . And so do, Microsoft . . Datasets we have discussed so far. They will definitely provide the edge you looking for (if you look correctly). They are almost all you need. Although there are sites like kaggle, datatruks but as we have mentioned google dataset engine. It automatically directs you to the sites. .",
            "url": "https://hiteshhedwig.github.io/hedwig-explains/dataset/opensource/2020/10/08/opensource-dataset.html",
            "relUrl": "/dataset/opensource/2020/10/08/opensource-dataset.html",
            "date": " • Oct 8, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Dog Breed Classification:",
            "content": "Intro: . We have used famous standford dataset. The Stanford Dogs dataset contains images of 120 breeds of dogs from around the world. This dataset has been built using images and annotation from ImageNet for the task of fine-grained image categorization. . I have downloaded it manually and uploaded to my google drive. Later made a webapp. . Fastai2: It&#39;s very famous A.I library built on the top of pytorch. Courses taught by himself Jeremey Howard here. Do go through it, it might look a bit long but it&#39;s worth it! . Before proceeding further, if you are a beginner, you should know that google colab comes with preinstalled libraries. So, we rarely have to install something on our own. But for this task, we will be using fastai2. And Installing it because its not pre-installed. . Gathering data and using: . Here, we are connecting our google colab notebook to google drive. So that, the data i have downloaded can be loaded and used for training. When you will download data the folder names i.e classes would be filled with numbers and special characters. But we want simple class name like, Pembroke not n02113023-Pembroke . So, a bit cleaning was necessary. In fastai, Jeremy Howard talks about using regular expression technique which is indeed quite handy. . But i haven&#39;t used it, i used simple custom function to change the names. Which worked pretty well! . You can find that blog here in this link. It&#39;s small and quick. . from google.colab import drive drive.mount(&quot;/content/gdrive&quot;) . Mounted at /content/gdrive . . Note: that at the time of running this notebook. Fastai2 was supported by fastcore 0.1.35 somehow. . !pip install fastai2 !pip install fastcore==0.1.35 . . Important: In standard software engineering practices, it is not recommended to use from {some package} import *. It is said to pollute namespace and make code less readable and sometimes prone to breakage. . from fastai2.vision.all import * . Then why are we using it? . According to the creator, Jeremy Howard, it&#39;s recommended way in fastai2. Fastai2 is designed in a way to make from fastai2.vision.all import * efficient and easy to use. It doesn&#39;t causes namespace pollution and keeps code clean. To learn about it more you can refer to fastai official docs. . Now, loading data from our dataset directory. Fastai provides pretty easy way to deal with it. . dls = ImageDataLoaders.from_folder(path,train=&#39;train&#39;, valid=&#39;val&#39;, item_tfms=Resize(460), batch_tfms=aug_transforms(size=224,flip_vert=True), device=&#39;cuda&#39;) . In fastai, if you are getting started. It might look a bit overwhelming to get familiar with words. Just like me, perhaps. But bear with it. It&#39;s worth it. . Now what is ImageDataLoaders.from_folder? Fastai has various dataloaders to take use data and convert them into batches and other type of augmentation. Look into this. These functions basically load your data and convert them in batches. Either, loading from folder, df, path func.. etc. We are using ImageDataLoaders.from_folder because we have image data saved in it. . Parameters of this functions like, path, train, val, item_tfms, batch_tfms. In first, we define path to the directory. Within the directory i have image folder named train and val. Giving these folders name to function so that it can go on finding the data. . item_tfms happens first, followed by batch_tfms. This enables most of the calculations for the transforms to happen on the GPU, thus saving time. The first step item_tfms resizes all the images to the same size (this happens on the CPU) and then batch_tfms happens on the GPU for the entire batch of images. If it weren’t to happen in two steps, then all these calculations would have to be done on the CPU, which is slower. . . As you can see, item_tfms uses CPU for resizing images to same size. So that, our model generalizes well. And then we use batch_tfms to push everything to GPU. . Now after data preprocessing. Shall we look into our data? How it looks. It&#39;s important to be familiar with data and get comfortable with it. . dls.show_batch() . . Modelling in Fastai2 . We use cnn_learner to built our model in single line. Although so many is happening under the hood. Remember that we aare passing several things like, dls which is our dataloader we created a while ago. resnet50 is our pretrained state of the art model. Incase, you are absolute beginner. We use technique called transfer learning. . What it does? It take pretrained. State of the art model. And fine tune it. It means, existing pretrained model and change several parameters according to our needs and MAGIC we get our own state of the art model. . This is what cnn_learner does. We give it data, and tells which model to use. We could also use resnet18,34,101. But in this case, resnet 50 worked pretty well. And we also pass metric to be used, remember metric is important parameter as it tells us our model is not overfitting. We used both error_rate and accuracy. In many cases, error_rate is your best friend. . learn = cnn_learner(dls, resnet50, metrics=[accuracy,error_rate]) . Before going to the training we should find learning rate at which model will be learning the data. . Warning: Don&#8217;t fall in trap of choosing high learning rate so that our model learns fastest. . Why? Because faster learning means model missing out the underlying relation in the data. Rather struggles and won&#39;t give you satisfactory result. Neither, we should choose low learning rate coz it might take eternity to reach to solution. We want abstemious learning rate so that it fits well. . . So, how to choose learning rate? Fastai to the rescue! . Below, an image will help you. Choosing learning rate. . learn.lr_find() . SuggestedLRs(lr_min=0.004786301031708717, lr_steep=0.009120108559727669) . Oops, It is some curvy graph. And we are provided with 2 suggested LR(Learning Rate) . How to choose best learning rate? You might hypothesis that learning rate which gives lowest would be ideal. . Not quite. We want to select learning rate point at which it is dropping fastest per step. This happening around near between 10^-3 and 10^-2. We can choose, 1e-3. Which in normal notations is 0.0010. . Model Training And Result . Well, now the time to have fun! Let&#39;s see how our model performs. I hope not too bad. We use fine_tune function to set number of epochs and learning rate. Let&#39;s set number of epochs to 4. . learn.fine_tune(4, 1e-3) . epoch train_loss valid_loss accuracy error_rate time . 0 | 1.477997 | 0.959091 | 0.719900 | 0.280100 | 02:48 | . epoch train_loss valid_loss accuracy error_rate time . 0 | 1.112022 | 0.758686 | 0.771144 | 0.228856 | 02:54 | . 1 | 0.913335 | 0.653243 | 0.800995 | 0.199005 | 02:55 | . 2 | 0.741961 | 0.605838 | 0.815920 | 0.184080 | 02:55 | . 3 | 0.636256 | 0.594278 | 0.828856 | 0.171144 | 02:57 | . Ummm, 82% accuracy. Not exceptional not bad either. Actually, it works very fine. You can do better! Try yourself and see if you can do better than this. . Let&#39;s see results below . learn.show_results() . . So our model is detecting pretty nicely?!!! Just one error. With so minimal effort we trained state of the art model and it is working pretty well. If you can train nicely, it will be flawless! . But, let&#39;s just look at where we are wrong. Where our model is making mistakes? . interp = Interpretation.from_learner(learn) interp.plot_top_losses(9, figsize=(15,10)) . . We can also plot confusion matrix. It helps us to see if the predictions are right or not. Below image shows some white diagonal. It means most of the images were classified correctly. If you want to learn more about confusion matrix read here. . k= ClassificationInterpretation.from_learner(learn) k.plot_confusion_matrix() . Let&#39;s just predict on any random image. I had test dataset which i didn&#39;t use in my training. So, using any one image. I chose, Beagle image. Let&#39;s see if our model can predict correctly. . . Tip: You can use softmax function to show the probability of prediction. . breed=learn.predict(img) . . &#34;Dog&#39;s Breed is Beagle&#34; . Exporting Model and Loading it . One of the questions could be how to export model? We use fairly easy way in exporting and loading models in fastai2. . learn.export(&#39;final.pth&#39;) #exporting . learn= load_learner(&#39;final.pth&#39;) #loading . Again using prediction to see if our model is still able to recognize Beagle image we used a while ago . &#34;Dog&#39;s Breed is Beagle&#34; . So, its working pretty nicely! . If it helped you or you have any queries feel free to ask! .",
            "url": "https://hiteshhedwig.github.io/hedwig-explains/python/deeplearning/classification/fastai/2020/10/08/dog-breed-fastai.html",
            "relUrl": "/python/deeplearning/classification/fastai/2020/10/08/dog-breed-fastai.html",
            "date": " • Oct 8, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://hiteshhedwig.github.io/hedwig-explains/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is a blogging website where i share things both technical and spiritual ideas under the penname of hedwig. Connect with me : . Linkedin . Website .",
          "url": "https://hiteshhedwig.github.io/hedwig-explains/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://hiteshhedwig.github.io/hedwig-explains/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}